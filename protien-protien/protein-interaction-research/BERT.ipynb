{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot enocoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = pd.read_csv(\"./positive.csv\")\n",
    "negatives = pd.read_csv(\"./negative.csv\")\n",
    "\n",
    "amino_acids = []\n",
    "\n",
    "def add_to_amino_acids(a_sequence: str):\n",
    "    for acid in a_sequence:\n",
    "        if acid not in amino_acids:\n",
    "            amino_acids.append(acid)\n",
    "\n",
    "positives.stack().reset_index(drop=True).apply(add_to_amino_acids)\n",
    "\n",
    "amino_acids.sort()\n",
    "\n",
    "amino_acid_label_encoder = LabelEncoder()\n",
    "amino_acid_label_encoder.fit(amino_acids)\n",
    "\n",
    "all_amino_acids = amino_acid_label_encoder.transform(amino_acids)\n",
    "\n",
    "def feature_map(p_sequence):\n",
    "    return [tf.one_hot(amino_acid_label_encoder.transform(list(x)), len(all_amino_acids)) for x in p_sequence]\n",
    "\n",
    "data_cd3r = feature_map(positives[\"cdr3\"])\n",
    "data_epitope = feature_map(positives[\"antigen.epitope\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForMaskedLM\n",
    "import keras\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convToArray(x):\n",
    "    return ' '.join(list(x))\n",
    "\n",
    "for column in positives.columns:\n",
    "    positives[column] = positives[column].apply(convToArray)\n",
    "def construct_sentences(dataframe):\n",
    "    cdr3_sentences = \"[CLS] \" + \" [SEP] \".join(dataframe[\"cdr3\"]) + \" [SEP]\"\n",
    "    epitope_sentences = \" [SEP] \".join(dataframe[\"antigen.epitope\"]) + \" [SEP]\"\n",
    "    return cdr3_sentences + epitope_sentences\n",
    "\n",
    "sentences = construct_sentences(positives)\n",
    "\n",
    "\n",
    "lengths_of_data = [len(sentence.split(\" \")) for sentence in sentences.split(\" [SEP] \")]\n",
    "\n",
    "def pad_sentence(sentence, max_length):\n",
    "    tokens = sentence.split()\n",
    "    if len(tokens) < max_length:\n",
    "        padding = \"[PAD]\" * (max_length - len(tokens))\n",
    "        return sentence + \" \" + padding\n",
    "    return sentence\n",
    "\n",
    "max_length = 1\n",
    "sentences = pad_sentence(sentences, max_length)\n",
    "\n",
    "train_data, test_data = train_test_split(sentences, test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
